{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tweepy as tw\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from tweepy import Stream                   # Useful in Step 4\n",
    "from tweepy.streaming import StreamListener # Useful in Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key= \n",
    "consumer_secret= \n",
    "access_token= \n",
    "access_token_secret= \n",
    "\n",
    "# complete authorization and initialize API endpoint\n",
    "if __name__ == \"__main__\":\n",
    "    auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tw.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StreamListener class inherits from tweepy.StreamListener and overrides on_status/on_error methods.\n",
    "class StreamListener(StreamListener):\n",
    "    def on_status(self, status):\n",
    "         \n",
    "        #print(status.id_str)\n",
    "        #if \"retweeted_status\" attribute exists, flag this tweet as a retweet.\n",
    "        #is_retweet = hasattr(status, \"retweeted_status\")\n",
    "        \n",
    "        # check if text has been truncated\n",
    "        if hasattr(status,\"extended_tweet\"):\n",
    "            text = status.extended_tweet[\"full_text\"]\n",
    "        else:\n",
    "            text = status.text\n",
    "            \n",
    "        text = text.replace('\\n',' ').encode(\"unicode-escape\").decode(\"utf-8\")\n",
    "             \n",
    "        with open(\"jio2.csv\", \"a\", encoding='utf-8') as f:\n",
    "            f.write(\"%s,%s,%s,%s,%s \\n\" % (status.id_str,status.created_at,search_string,status.user.screen_name,text))\n",
    "           \n",
    "    def on_error(self, status_code):\n",
    "        print(\"Encountered streaming error (\", status_code, \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list=[]\n",
    "search_string = \"@Jiocare\"\n",
    "\n",
    "with open(\"jio2.csv\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(\"ID,Date,Vertex1,User,Tweet \\n\")\n",
    "        \n",
    "stream_listener = StreamListener()\n",
    "stream = tw.Stream(auth=api.auth, listener=stream_listener,tweet_mode='extened',stream=True)\n",
    "\n",
    "stream.filter(track=[\"@jiocare\"])\n",
    "#stream.filter(track=[\"@airtelindia\", \"@airtel_presence\", \"@AirtelPresence\"])\n",
    "        \n",
    "#except Exception as e:\n",
    "#    print(\"Error: \",str(e))\n",
    "#    time.sleep(200)\n",
    "#    pass\n",
    "        \n",
    "#except Exception as e:\n",
    "#    print(\"Error:\", str(e))\n",
    "#    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect tweets - using the python lists \n",
    "#tweets = tw.Cursor(api.search, q=search_words, tweet_mode='extended', lang=\"en\", since=date_since).items(2)\n",
    "\n",
    "# Define the search term and the date_since date as variables\n",
    "search_words = \"@hathwayBrdband\"\n",
    "#date_since = \"2021-01-01\"\n",
    "userID = \"hath_02Oct_2\"\n",
    "# Collect a list of tweets\n",
    "#search_tweets = api.search(q=search_words,since=date_since,count=6,lang='en',tweet_mode='extended')\n",
    "search_tweets = api.search(q=search_words,lang='en',tweet_mode='extended',count=500)\n",
    "#for tweet in search_tweets:\n",
    "    #u = tweet.full_text.encode(\"unicode-escape\").decode(\"utf-8\").replace('\\n',' ')\n",
    "    #u = u.replace('\\n', ' ')\n",
    "    #print(tweet.full_text.replace('\\n',' ').encode(\"unicode-escape\").decode(\"utf-8\")) \n",
    "    #print(tweet.full_text.ecode(\"unicode-escape\").decode(\"utf-8\"))\n",
    "    #print(\"ID: {}\".format(tweet.id_str))\n",
    "    #print(tweet.created_at)\n",
    "    #print(tweet.user.screen_name)\n",
    "    #print(\"\\n\")\n",
    "    \n",
    "tweets_list = [[tweet.id_str, tweet.created_at,search_words,tweet.user.screen_name, tweet.full_text.replace('\\n', ' ').encode(\"unicode-escape\").decode(\"utf-8\")] for tweet in search_tweets]\n",
    "#save tweets into a csv file\n",
    "tweets_df = pd.DataFrame(data=tweets_list,columns=['TweetID','Date','Vertex1','Customer Handle','Tweet']) \n",
    "tweets_df.to_csv('%s_tweets.csv' % userID,index=False)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the file again\n",
    "read_df= pd.read_csv(r'C:/Users/Tanisha Batra/Airtel_tweets.csv', encoding='unicode-escape')\n",
    "#read_df= pd.read_csv(r'C:/Users/Tanisha Batra/Airtel_tweets.csv',encoding='utf-8', parse_dates=[1])\n",
    "read_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
